{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQso4cv8PDWT"
   },
   "source": [
    "# Previsão Idade Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook será levada uma abordagem diferente ao problema até aqui exposto. Neste decidimos, apesar de continuar a considerar este um problema de classifação, testar um modelo de regressão para a previsão de idade. \n",
    "\n",
    "\n",
    "Tal como nos notebooks passados, é preciso, numa fase inicial, carregar os dados dos ficheiros previamente criados. De seguida será feita a separação dos dados para treino/teste e por fim testar-se-á o sucesso da rede.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TxMNjKzAOnrj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperação dos dados dos ficheiros relativamente as imagens/labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do ficheiro csv correspondente a todas as labels e anexação destas a lista results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIVPunlYPIbt"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "with open(\"5kLabelsNoBins.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile, quoting=csv.QUOTE_ALL) # change contents to floats\n",
    "    for row in reader: # each row is a list\n",
    "        results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GpFY6ectPIi9",
    "outputId": "ca27da38-60ac-41ab-ae08-4fc38d3f81cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['24'],\n",
       " ['38'],\n",
       " ['20'],\n",
       " ['21'],\n",
       " ['24'],\n",
       " ['53'],\n",
       " ['38'],\n",
       " ['32'],\n",
       " ['45'],\n",
       " ['60'],\n",
       " ['29'],\n",
       " ['34'],\n",
       " ['25'],\n",
       " ['46'],\n",
       " ['63'],\n",
       " ['23'],\n",
       " ['53'],\n",
       " ['27'],\n",
       " ['50'],\n",
       " ['26'],\n",
       " ['45'],\n",
       " ['26'],\n",
       " ['44'],\n",
       " ['43'],\n",
       " ['46'],\n",
       " ['25'],\n",
       " ['56'],\n",
       " ['39'],\n",
       " ['22'],\n",
       " ['52'],\n",
       " ['20'],\n",
       " ['28'],\n",
       " ['32'],\n",
       " ['48'],\n",
       " ['22'],\n",
       " ['49'],\n",
       " ['64'],\n",
       " ['32'],\n",
       " ['19'],\n",
       " ['30'],\n",
       " ['40'],\n",
       " ['43'],\n",
       " ['22'],\n",
       " ['24'],\n",
       " ['30'],\n",
       " ['40'],\n",
       " ['18'],\n",
       " ['57'],\n",
       " ['25'],\n",
       " ['25'],\n",
       " ['19'],\n",
       " ['41'],\n",
       " ['46'],\n",
       " ['23'],\n",
       " ['39'],\n",
       " ['24'],\n",
       " ['51'],\n",
       " ['25'],\n",
       " ['24'],\n",
       " ['55'],\n",
       " ['53'],\n",
       " ['47'],\n",
       " ['65'],\n",
       " ['41'],\n",
       " ['35'],\n",
       " ['40'],\n",
       " ['30'],\n",
       " ['48'],\n",
       " ['20'],\n",
       " ['36'],\n",
       " ['29'],\n",
       " ['27'],\n",
       " ['35'],\n",
       " ['45'],\n",
       " ['51'],\n",
       " ['28'],\n",
       " ['43'],\n",
       " ['18'],\n",
       " ['25'],\n",
       " ['28'],\n",
       " ['31'],\n",
       " ['43'],\n",
       " ['34'],\n",
       " ['20'],\n",
       " ['31'],\n",
       " ['21'],\n",
       " ['35'],\n",
       " ['22'],\n",
       " ['25'],\n",
       " ['34'],\n",
       " ['62'],\n",
       " ['32'],\n",
       " ['30'],\n",
       " ['26'],\n",
       " ['35'],\n",
       " ['33'],\n",
       " ['41'],\n",
       " ['30'],\n",
       " ['39'],\n",
       " ['52'],\n",
       " ['28'],\n",
       " ['27'],\n",
       " ['58'],\n",
       " ['19'],\n",
       " ['33'],\n",
       " ['23'],\n",
       " ['43'],\n",
       " ['25'],\n",
       " ['30'],\n",
       " ['45'],\n",
       " ['21'],\n",
       " ['40'],\n",
       " ['54'],\n",
       " ['24'],\n",
       " ['55'],\n",
       " ['27'],\n",
       " ['47'],\n",
       " ['45'],\n",
       " ['46'],\n",
       " ['42'],\n",
       " ['42'],\n",
       " ['20'],\n",
       " ['49'],\n",
       " ['46'],\n",
       " ['36'],\n",
       " ['30'],\n",
       " ['25'],\n",
       " ['34'],\n",
       " ['20'],\n",
       " ['57'],\n",
       " ['53'],\n",
       " ['47'],\n",
       " ['20'],\n",
       " ['54'],\n",
       " ['61'],\n",
       " ['51'],\n",
       " ['25'],\n",
       " ['27'],\n",
       " ['44'],\n",
       " ['22'],\n",
       " ['27'],\n",
       " ['39'],\n",
       " ['28'],\n",
       " ['23'],\n",
       " ['22'],\n",
       " ['26'],\n",
       " ['25'],\n",
       " ['48'],\n",
       " ['30'],\n",
       " ['29'],\n",
       " ['22'],\n",
       " ['44'],\n",
       " ['25'],\n",
       " ['24'],\n",
       " ['25'],\n",
       " ['30'],\n",
       " ['21'],\n",
       " ['45'],\n",
       " ['25'],\n",
       " ['57'],\n",
       " ['25'],\n",
       " ['40'],\n",
       " ['32'],\n",
       " ['22'],\n",
       " ['22'],\n",
       " ['37'],\n",
       " ['46'],\n",
       " ['37'],\n",
       " ['43'],\n",
       " ['28'],\n",
       " ['26'],\n",
       " ['25'],\n",
       " ['26'],\n",
       " ['53'],\n",
       " ['23'],\n",
       " ['37'],\n",
       " ['32'],\n",
       " ['38'],\n",
       " ['39'],\n",
       " ['51'],\n",
       " ['27'],\n",
       " ['56'],\n",
       " ['30'],\n",
       " ['18'],\n",
       " ['48'],\n",
       " ['59'],\n",
       " ['64'],\n",
       " ['27'],\n",
       " ['52'],\n",
       " ['55'],\n",
       " ['49'],\n",
       " ['43'],\n",
       " ['64'],\n",
       " ['27'],\n",
       " ['48'],\n",
       " ['41'],\n",
       " ['32'],\n",
       " ['46'],\n",
       " ['23'],\n",
       " ['23'],\n",
       " ['20'],\n",
       " ['29'],\n",
       " ['47'],\n",
       " ['40'],\n",
       " ['29'],\n",
       " ['50'],\n",
       " ['45'],\n",
       " ['61'],\n",
       " ['51'],\n",
       " ['28'],\n",
       " ['31'],\n",
       " ['26'],\n",
       " ['58'],\n",
       " ['63'],\n",
       " ['33'],\n",
       " ['23'],\n",
       " ['27'],\n",
       " ['58'],\n",
       " ['24'],\n",
       " ['34'],\n",
       " ['32'],\n",
       " ['36'],\n",
       " ['32'],\n",
       " ['18'],\n",
       " ['32'],\n",
       " ['57'],\n",
       " ['27'],\n",
       " ['33'],\n",
       " ['25'],\n",
       " ['51'],\n",
       " ['52'],\n",
       " ['34'],\n",
       " ['26'],\n",
       " ['56'],\n",
       " ['24'],\n",
       " ['18'],\n",
       " ['28'],\n",
       " ['21'],\n",
       " ['35'],\n",
       " ['28'],\n",
       " ['42'],\n",
       " ['31'],\n",
       " ['25'],\n",
       " ['49'],\n",
       " ['26'],\n",
       " ['39'],\n",
       " ['30'],\n",
       " ['35'],\n",
       " ['57'],\n",
       " ['29'],\n",
       " ['32'],\n",
       " ['30'],\n",
       " ['40'],\n",
       " ['24'],\n",
       " ['29'],\n",
       " ['27'],\n",
       " ['23'],\n",
       " ['56'],\n",
       " ['23'],\n",
       " ['28'],\n",
       " ['33'],\n",
       " ['35'],\n",
       " ['22'],\n",
       " ['61'],\n",
       " ['56'],\n",
       " ['25'],\n",
       " ['61'],\n",
       " ['42'],\n",
       " ['27'],\n",
       " ['21'],\n",
       " ['28'],\n",
       " ['45'],\n",
       " ['27'],\n",
       " ['23'],\n",
       " ['55'],\n",
       " ['25'],\n",
       " ['28'],\n",
       " ['27'],\n",
       " ['20'],\n",
       " ['23'],\n",
       " ['25'],\n",
       " ['34'],\n",
       " ['30'],\n",
       " ['25'],\n",
       " ['42'],\n",
       " ['36'],\n",
       " ['21'],\n",
       " ['52'],\n",
       " ['28'],\n",
       " ['20'],\n",
       " ['36'],\n",
       " ['24'],\n",
       " ['51'],\n",
       " ['58'],\n",
       " ['23'],\n",
       " ['49'],\n",
       " ['24'],\n",
       " ['37'],\n",
       " ['31'],\n",
       " ['62'],\n",
       " ['49'],\n",
       " ['29'],\n",
       " ['28'],\n",
       " ['28'],\n",
       " ['31'],\n",
       " ['37'],\n",
       " ['32'],\n",
       " ['21'],\n",
       " ['49'],\n",
       " ['22'],\n",
       " ['43'],\n",
       " ['50'],\n",
       " ['55'],\n",
       " ['59'],\n",
       " ['31'],\n",
       " ['41'],\n",
       " ['32'],\n",
       " ['37'],\n",
       " ['21'],\n",
       " ['60'],\n",
       " ['34'],\n",
       " ['37'],\n",
       " ['42'],\n",
       " ['28'],\n",
       " ['30'],\n",
       " ['41'],\n",
       " ['29'],\n",
       " ['35'],\n",
       " ['51'],\n",
       " ['21'],\n",
       " ['45'],\n",
       " ['58'],\n",
       " ['34'],\n",
       " ['31'],\n",
       " ['33'],\n",
       " ['37'],\n",
       " ['26'],\n",
       " ['30'],\n",
       " ['20'],\n",
       " ['18'],\n",
       " ['30'],\n",
       " ['41'],\n",
       " ['24'],\n",
       " ['30'],\n",
       " ['36'],\n",
       " ['58'],\n",
       " ['64'],\n",
       " ['39'],\n",
       " ['25'],\n",
       " ['29'],\n",
       " ['38'],\n",
       " ['56'],\n",
       " ['25'],\n",
       " ['56'],\n",
       " ['25'],\n",
       " ['20'],\n",
       " ['30'],\n",
       " ['21'],\n",
       " ['49'],\n",
       " ['28'],\n",
       " ['49'],\n",
       " ['21'],\n",
       " ['26'],\n",
       " ['46'],\n",
       " ['27'],\n",
       " ['41'],\n",
       " ['27'],\n",
       " ['20'],\n",
       " ['31'],\n",
       " ['26'],\n",
       " ['28'],\n",
       " ['64'],\n",
       " ['18'],\n",
       " ['29'],\n",
       " ['28'],\n",
       " ['19'],\n",
       " ['22'],\n",
       " ['45'],\n",
       " ['39'],\n",
       " ['35'],\n",
       " ['38'],\n",
       " ['29'],\n",
       " ['33'],\n",
       " ['21'],\n",
       " ['27'],\n",
       " ['46'],\n",
       " ['21'],\n",
       " ['25'],\n",
       " ['25'],\n",
       " ['20'],\n",
       " ['41'],\n",
       " ['33'],\n",
       " ['62'],\n",
       " ['21'],\n",
       " ['24'],\n",
       " ['27'],\n",
       " ['33'],\n",
       " ['49'],\n",
       " ['24'],\n",
       " ['29'],\n",
       " ['27'],\n",
       " ['34'],\n",
       " ['25'],\n",
       " ['39'],\n",
       " ['30'],\n",
       " ['46'],\n",
       " ['26'],\n",
       " ['24'],\n",
       " ['24'],\n",
       " ['49'],\n",
       " ['25'],\n",
       " ['24'],\n",
       " ['21'],\n",
       " ['39'],\n",
       " ['18'],\n",
       " ['39'],\n",
       " ['49'],\n",
       " ['40'],\n",
       " ['27'],\n",
       " ['25'],\n",
       " ['24'],\n",
       " ['33'],\n",
       " ['55'],\n",
       " ['44'],\n",
       " ['37'],\n",
       " ['28'],\n",
       " ['45'],\n",
       " ['36'],\n",
       " ['60'],\n",
       " ['63'],\n",
       " ['32'],\n",
       " ['65'],\n",
       " ['33'],\n",
       " ['18'],\n",
       " ['62'],\n",
       " ['36'],\n",
       " ['36'],\n",
       " ['31'],\n",
       " ['27'],\n",
       " ['24'],\n",
       " ['45'],\n",
       " ['53'],\n",
       " ['63'],\n",
       " ['44'],\n",
       " ['51'],\n",
       " ['38'],\n",
       " ['36'],\n",
       " ['26'],\n",
       " ['31'],\n",
       " ['26'],\n",
       " ['20'],\n",
       " ['35'],\n",
       " ['24'],\n",
       " ['25'],\n",
       " ['41'],\n",
       " ['37'],\n",
       " ['33'],\n",
       " ['22'],\n",
       " ['26'],\n",
       " ['25'],\n",
       " ['29'],\n",
       " ['40'],\n",
       " ['20'],\n",
       " ['24'],\n",
       " ['33'],\n",
       " ['25'],\n",
       " ['27'],\n",
       " ['28'],\n",
       " ['29'],\n",
       " ['29'],\n",
       " ['49'],\n",
       " ['39'],\n",
       " ['29'],\n",
       " ['42'],\n",
       " ['29'],\n",
       " ['39'],\n",
       " ['22'],\n",
       " ['62'],\n",
       " ['28'],\n",
       " ['25'],\n",
       " ['21'],\n",
       " ['27'],\n",
       " ['56'],\n",
       " ['27'],\n",
       " ['29'],\n",
       " ['34'],\n",
       " ['57'],\n",
       " ['36'],\n",
       " ['31'],\n",
       " ['43'],\n",
       " ['33'],\n",
       " ['29'],\n",
       " ['20'],\n",
       " ['53'],\n",
       " ['57'],\n",
       " ['24'],\n",
       " ['36'],\n",
       " ['58'],\n",
       " ['43'],\n",
       " ['49'],\n",
       " ['44'],\n",
       " ['38'],\n",
       " ['40'],\n",
       " ['27'],\n",
       " ['40'],\n",
       " ['28'],\n",
       " ['26'],\n",
       " ['39'],\n",
       " ['46'],\n",
       " ['23'],\n",
       " ['26'],\n",
       " ['33'],\n",
       " ['35'],\n",
       " ['49'],\n",
       " ['26'],\n",
       " ['44'],\n",
       " ['47'],\n",
       " ['32'],\n",
       " ['22'],\n",
       " ['25'],\n",
       " ['42'],\n",
       " ['26'],\n",
       " ['44'],\n",
       " ['43'],\n",
       " ['23'],\n",
       " ['35'],\n",
       " ['29'],\n",
       " ['24'],\n",
       " ['53'],\n",
       " ['64'],\n",
       " ['51'],\n",
       " ['47'],\n",
       " ['37'],\n",
       " ['31'],\n",
       " ['35'],\n",
       " ['63'],\n",
       " ['29'],\n",
       " ['24'],\n",
       " ['32'],\n",
       " ['27'],\n",
       " ['29'],\n",
       " ['27'],\n",
       " ['23'],\n",
       " ['56'],\n",
       " ['27'],\n",
       " ['43'],\n",
       " ['31'],\n",
       " ['23'],\n",
       " ['50'],\n",
       " ['60'],\n",
       " ['19'],\n",
       " ['33'],\n",
       " ['30'],\n",
       " ['23'],\n",
       " ['54'],\n",
       " ['24'],\n",
       " ['49'],\n",
       " ['25'],\n",
       " ['22'],\n",
       " ['21'],\n",
       " ['27'],\n",
       " ['55'],\n",
       " ['43'],\n",
       " ['44'],\n",
       " ['33'],\n",
       " ['22'],\n",
       " ['26'],\n",
       " ['64'],\n",
       " ['22'],\n",
       " ['34'],\n",
       " ['29'],\n",
       " ['37'],\n",
       " ['40'],\n",
       " ['22'],\n",
       " ['25'],\n",
       " ['63'],\n",
       " ['36'],\n",
       " ['26'],\n",
       " ['27'],\n",
       " ['30'],\n",
       " ['33'],\n",
       " ['58'],\n",
       " ['26'],\n",
       " ['28'],\n",
       " ['30'],\n",
       " ['34'],\n",
       " ['22'],\n",
       " ['57'],\n",
       " ['22'],\n",
       " ['43'],\n",
       " ['57'],\n",
       " ['23'],\n",
       " ['23'],\n",
       " ['45'],\n",
       " ['49'],\n",
       " ['29'],\n",
       " ['18'],\n",
       " ['32'],\n",
       " ['50'],\n",
       " ['29'],\n",
       " ['53'],\n",
       " ['38'],\n",
       " ['35'],\n",
       " ['60'],\n",
       " ['30'],\n",
       " ['22'],\n",
       " ['20'],\n",
       " ['44'],\n",
       " ['41'],\n",
       " ['30'],\n",
       " ['20'],\n",
       " ['46'],\n",
       " ['30'],\n",
       " ['36'],\n",
       " ['23'],\n",
       " ['55'],\n",
       " ['23'],\n",
       " ['33'],\n",
       " ['23'],\n",
       " ['54'],\n",
       " ['25'],\n",
       " ['21'],\n",
       " ['28'],\n",
       " ['35'],\n",
       " ['26'],\n",
       " ['27'],\n",
       " ['30'],\n",
       " ['65'],\n",
       " ['18'],\n",
       " ['20'],\n",
       " ['46'],\n",
       " ['30'],\n",
       " ['38'],\n",
       " ['21'],\n",
       " ['22'],\n",
       " ['29'],\n",
       " ['26'],\n",
       " ['26'],\n",
       " ['40'],\n",
       " ['50'],\n",
       " ['34'],\n",
       " ['33'],\n",
       " ['45'],\n",
       " ['47'],\n",
       " ['30'],\n",
       " ['26'],\n",
       " ['21'],\n",
       " ['34'],\n",
       " ['22'],\n",
       " ['37'],\n",
       " ['30'],\n",
       " ['22'],\n",
       " ['45'],\n",
       " ['32'],\n",
       " ['35'],\n",
       " ['54'],\n",
       " ['19'],\n",
       " ['40'],\n",
       " ['21'],\n",
       " ['33'],\n",
       " ['35'],\n",
       " ['43'],\n",
       " ['60'],\n",
       " ['40'],\n",
       " ['52'],\n",
       " ['23'],\n",
       " ['23'],\n",
       " ['18'],\n",
       " ['26'],\n",
       " ['45'],\n",
       " ['50'],\n",
       " ['22'],\n",
       " ['59'],\n",
       " ['21'],\n",
       " ['42'],\n",
       " ['27'],\n",
       " ['40'],\n",
       " ['27'],\n",
       " ['18'],\n",
       " ['24'],\n",
       " ['23'],\n",
       " ['25'],\n",
       " ['26'],\n",
       " ['32'],\n",
       " ['27'],\n",
       " ['50'],\n",
       " ['42'],\n",
       " ['48'],\n",
       " ['64'],\n",
       " ['57'],\n",
       " ['33'],\n",
       " ['46'],\n",
       " ['26'],\n",
       " ['22'],\n",
       " ['29'],\n",
       " ['28'],\n",
       " ['31'],\n",
       " ['26'],\n",
       " ['47'],\n",
       " ['44'],\n",
       " ['22'],\n",
       " ['41'],\n",
       " ['35'],\n",
       " ['40'],\n",
       " ['21'],\n",
       " ['35'],\n",
       " ['24'],\n",
       " ['45'],\n",
       " ['33'],\n",
       " ['23'],\n",
       " ['44'],\n",
       " ['20'],\n",
       " ['41'],\n",
       " ['40'],\n",
       " ['22'],\n",
       " ['52'],\n",
       " ['23'],\n",
       " ['25'],\n",
       " ['60'],\n",
       " ['55'],\n",
       " ['33'],\n",
       " ['19'],\n",
       " ['34'],\n",
       " ['36'],\n",
       " ['30'],\n",
       " ['47'],\n",
       " ['58'],\n",
       " ['22'],\n",
       " ['30'],\n",
       " ['63'],\n",
       " ['33'],\n",
       " ['43'],\n",
       " ['21'],\n",
       " ['19'],\n",
       " ['58'],\n",
       " ['37'],\n",
       " ['25'],\n",
       " ['32'],\n",
       " ['52'],\n",
       " ['34'],\n",
       " ['47'],\n",
       " ['21'],\n",
       " ['58'],\n",
       " ['53'],\n",
       " ['54'],\n",
       " ['36'],\n",
       " ['53'],\n",
       " ['24'],\n",
       " ['19'],\n",
       " ['32'],\n",
       " ['27'],\n",
       " ['36'],\n",
       " ['18'],\n",
       " ['23'],\n",
       " ['33'],\n",
       " ['24'],\n",
       " ['23'],\n",
       " ['23'],\n",
       " ['27'],\n",
       " ['27'],\n",
       " ['22'],\n",
       " ['24'],\n",
       " ['57'],\n",
       " ['29'],\n",
       " ['34'],\n",
       " ['55'],\n",
       " ['55'],\n",
       " ['41'],\n",
       " ['65'],\n",
       " ['31'],\n",
       " ['45'],\n",
       " ['40'],\n",
       " ['41'],\n",
       " ['46'],\n",
       " ['49'],\n",
       " ['20'],\n",
       " ['32'],\n",
       " ['22'],\n",
       " ['32'],\n",
       " ['30'],\n",
       " ['18'],\n",
       " ['57'],\n",
       " ['35'],\n",
       " ['34'],\n",
       " ['25'],\n",
       " ['40'],\n",
       " ['50'],\n",
       " ['41'],\n",
       " ['25'],\n",
       " ['28'],\n",
       " ['26'],\n",
       " ['52'],\n",
       " ['34'],\n",
       " ['61'],\n",
       " ['27'],\n",
       " ['49'],\n",
       " ['31'],\n",
       " ['42'],\n",
       " ['31'],\n",
       " ['35'],\n",
       " ['41'],\n",
       " ['38'],\n",
       " ['55'],\n",
       " ['45'],\n",
       " ['39'],\n",
       " ['29'],\n",
       " ['47'],\n",
       " ['30'],\n",
       " ['21'],\n",
       " ['27'],\n",
       " ['47'],\n",
       " ['40'],\n",
       " ['62'],\n",
       " ['58'],\n",
       " ['25'],\n",
       " ['42'],\n",
       " ['23'],\n",
       " ['32'],\n",
       " ['38'],\n",
       " ['44'],\n",
       " ['56'],\n",
       " ['53'],\n",
       " ['32'],\n",
       " ['33'],\n",
       " ['38'],\n",
       " ['27'],\n",
       " ['22'],\n",
       " ['38'],\n",
       " ['22'],\n",
       " ['30'],\n",
       " ['29'],\n",
       " ['25'],\n",
       " ['22'],\n",
       " ['30'],\n",
       " ['33'],\n",
       " ['18'],\n",
       " ['33'],\n",
       " ['62'],\n",
       " ['50'],\n",
       " ['28'],\n",
       " ['20'],\n",
       " ['64'],\n",
       " ['65'],\n",
       " ['20'],\n",
       " ['52'],\n",
       " ['64'],\n",
       " ['31'],\n",
       " ['28'],\n",
       " ['49'],\n",
       " ['38'],\n",
       " ['32'],\n",
       " ['27'],\n",
       " ['20'],\n",
       " ['34'],\n",
       " ['21'],\n",
       " ['29'],\n",
       " ['27'],\n",
       " ['26'],\n",
       " ['23'],\n",
       " ['24'],\n",
       " ['28'],\n",
       " ['52'],\n",
       " ['51'],\n",
       " ['34'],\n",
       " ['39'],\n",
       " ['42'],\n",
       " ['27'],\n",
       " ['24'],\n",
       " ['49'],\n",
       " ['44'],\n",
       " ['65'],\n",
       " ['59'],\n",
       " ['55'],\n",
       " ['49'],\n",
       " ['21'],\n",
       " ['19'],\n",
       " ['32'],\n",
       " ['27'],\n",
       " ['42'],\n",
       " ['37'],\n",
       " ['35'],\n",
       " ['22'],\n",
       " ['52'],\n",
       " ['23'],\n",
       " ['37'],\n",
       " ['36'],\n",
       " ['55'],\n",
       " ['59'],\n",
       " ['39'],\n",
       " ['21'],\n",
       " ['49'],\n",
       " ['55'],\n",
       " ['26'],\n",
       " ['43'],\n",
       " ['27'],\n",
       " ['18'],\n",
       " ['46'],\n",
       " ['42'],\n",
       " ['65'],\n",
       " ['27'],\n",
       " ['36'],\n",
       " ['56'],\n",
       " ['29'],\n",
       " ['27'],\n",
       " ['52'],\n",
       " ['26'],\n",
       " ['25'],\n",
       " ['51'],\n",
       " ['59'],\n",
       " ['31'],\n",
       " ['22'],\n",
       " ['44'],\n",
       " ['34'],\n",
       " ['50'],\n",
       " ['55'],\n",
       " ['32'],\n",
       " ['43'],\n",
       " ['33'],\n",
       " ['47'],\n",
       " ['26'],\n",
       " ['33'],\n",
       " ['41'],\n",
       " ['26'],\n",
       " ['35'],\n",
       " ['25'],\n",
       " ['29'],\n",
       " ['30'],\n",
       " ['30'],\n",
       " ['52'],\n",
       " ['31'],\n",
       " ['22'],\n",
       " ['29'],\n",
       " ['23'],\n",
       " ['39'],\n",
       " ['19'],\n",
       " ['24'],\n",
       " ['46'],\n",
       " ['34'],\n",
       " ['45'],\n",
       " ['31'],\n",
       " ['24'],\n",
       " ['59'],\n",
       " ['26'],\n",
       " ['27'],\n",
       " ['47'],\n",
       " ['25'],\n",
       " ['46'],\n",
       " ['48'],\n",
       " ['50'],\n",
       " ['52'],\n",
       " ['44'],\n",
       " ['29'],\n",
       " ['24'],\n",
       " ['24'],\n",
       " ['32'],\n",
       " ['35'],\n",
       " ['59'],\n",
       " ['24'],\n",
       " ['44'],\n",
       " ['24'],\n",
       " ['39'],\n",
       " ['29'],\n",
       " ['44'],\n",
       " ['60'],\n",
       " ['43'],\n",
       " ['50'],\n",
       " ['53'],\n",
       " ['26'],\n",
       " ['29'],\n",
       " ['32'],\n",
       " ['38'],\n",
       " ['45'],\n",
       " ['20'],\n",
       " ['62'],\n",
       " ['20'],\n",
       " ['38'],\n",
       " ['51'],\n",
       " ['29'],\n",
       " ['36'],\n",
       " ['48'],\n",
       " ['59'],\n",
       " ['25'],\n",
       " ['64'],\n",
       " ['24'],\n",
       " ['24'],\n",
       " ['44'],\n",
       " ['22'],\n",
       " ['35'],\n",
       " ['37'],\n",
       " ['43'],\n",
       " ['50'],\n",
       " ['31'],\n",
       " ['24'],\n",
       " ['31'],\n",
       " ['28'],\n",
       " ['53'],\n",
       " ['35'],\n",
       " ['24'],\n",
       " ['32'],\n",
       " ['47'],\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta notebook, não se irá utilizar bins, visto que o iremos abordar como um problema de regressão. Deste modo preserva-se as labels como vieram (com a idade absoluta de cada pessoa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do ficheiro relativo aos pontos das fotos\n",
    "Neste caso foi utilizado o que possuia metade da informação do dataset (13877 fotos).\n",
    "Este foi guardado em ficheiro binario por uma questão de redução de dimensao (uma vez que este contem 13877 * 256 * 256 floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M61f-DDGPIZ4"
   },
   "outputs": [],
   "source": [
    "teste = np.reshape(np.fromfile(\"5kDataNoBins\"),(5642,256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos dados para treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que é necessária uma divisão do dataset para treino e teste, utilizamos o train_test_split com a flag de stratify (garantindo que a distribuição dos dados se mantem nas versões \"reduzidas\") e com random_state, permitindo assim que a operação se torna deterministica (os mesmos dados irao ser divididos sempre para os mesmos conjuntos de treino e teste, enquanto que o valor desta flag se mantenha constante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XE6n9XFfPIeV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(teste,results, test_size=0.15, stratify=results, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZcaO6XhQAs6"
   },
   "outputs": [],
   "source": [
    "#Reshape para 4 dimensões (nFotos * 256pixeis * 256 pixeis * 1 canal de cor(black&white))\n",
    "train_images = X_train.reshape((4795, 256, 256, 1))\n",
    "test_images = X_test.reshape((847, 256, 256, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que agora é um problema de regressão em que iremos usar a idade absoluta, as labels deixam de ser one-hot-enconding(um array com a dimensão das classes) e passa a ser apenas o respetivo valor da idade. Deste modo as novas labels sao apenas um array com todas as idades dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "As-V-HxGSEZx"
   },
   "outputs": [],
   "source": [
    "train_labels = np.asarray(y_train).astype('float32')\n",
    "test_labels = np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação e treino da rede\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raFTaauTDNw1"
   },
   "source": [
    "Tendo todos os dados carregados e prontos para passar a rede, podemos seguir para a contrução e treino da mesma. Uma vez que esta é uma abordagem diferente, consideramos relevante a utilização de duas diferentes redes (de modo a melhor verificar a possibilidade de utilização destas). Inicialmente utilizamos uma rede mais simples para o processamento e posteriormente uma da api do KERAS, sendo assim mais complexa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede Simplificada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcGLsobEQAzi"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "qCTq7rMYQA2I",
    "outputId": "0fe454d8-0598-45bb-b27b-af0f86dc0e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 254, 254, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,086,337\n",
      "Trainable params: 13,086,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das métricas do modelo, \"standard\" para este problema de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ND0thz2sQA5r"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mean_absolute_percentage_error',metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "EK8w-wmdRjeJ",
    "outputId": "aebbf98b-3cb5-461c-b82b-cf7ce117cdbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 16s 53ms/step - loss: 33.3940 - mse: 291.4330 - mae: 12.7307\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 27.7240 - mse: 206.3125 - mae: 10.8658\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 26.9398 - mse: 200.1065 - mae: 10.6461\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 26.6408 - mse: 197.8129 - mae: 10.5581\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 26.4321 - mse: 193.9965 - mae: 10.4335\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 26.0806 - mse: 187.1297 - mae: 10.2588\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 25.5495 - mse: 178.8887 - mae: 10.0146\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 25.2176 - mse: 169.6945 - mae: 9.7797\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 16s 53ms/step - loss: 24.6944 - mse: 165.3688 - mae: 9.6014\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 24.0254 - mse: 155.4316 - mae: 9.2597\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,train_labels, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jzwDJCASnPb4",
    "outputId": "471fa0ca-5524-4c03-f683-01710f0b1292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 33ms/step - loss: 24.8467 - mse: 185.7237 - mae: 10.1092\n"
     ]
    }
   ],
   "source": [
    "test_loss,a,b = model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1hDbtuDQZRq"
   },
   "source": [
    "### ResNet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a criação de uma rede ResNet é possível utilizar a API do Keras, passando como argumento os parametros mais importantes para a rede tais como:\n",
    "   * include_top => inclusão de uma camada completamente conetada no topo da rede\n",
    "   * weights => pesos relativos aos neuronios (neste caso começo aleatório, em vez de uso de uma rede pré-treinada)\n",
    "   * input_tensor => utilização de um tensor do Keras para utilização de imagens (desnecessário para o problema em questão)\n",
    "   * input_shape => formato do input à rede (tal como referido anteriormente (256,256,1) -> 256pixeis * 256pixeis *1 canal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtvHGLi2BWY8"
   },
   "outputs": [],
   "source": [
    "model_resnet = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(256,256,1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_F_ximhxddh0",
    "outputId": "e2c7c86a-8c17-4d4c-d245-4c584ed8bd23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 1)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 3200        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,581,440\n",
      "Trainable params: 23,528,320\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aJqto7obBWci",
    "outputId": "cdc6c642-7942-4f3d-bc31-850b62e25c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 1)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 3200        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 131072)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8388672     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            65          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 31,970,177\n",
      "Trainable params: 31,917,057\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = layers.Flatten()(model_resnet.output)\n",
    "x = layers.Dense(64, activation= 'relu')(x)\n",
    "x = layers.Dense(1, activation= 'linear')(x)\n",
    "resnet = models.Model(inputs = model_resnet.input, outputs = x)\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das métricas do modelo, \"standard\" para este problema de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOxwK-DcfxNG"
   },
   "outputs": [],
   "source": [
    "resnet.compile(optimizer='rmsprop', loss='mean_absolute_percentage_error', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "n7ulZrH8fxdQ",
    "outputId": "ef04079e-033b-4e36-86d8-f7ae32cbffed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "255/255 [==============================] - 63s 249ms/step - loss: 60.4515 - mse: 7915.1997 - mae: 20.2389 - val_loss: 27.1692 - val_mse: 245.6211 - val_mae: 11.5265\n",
      "Epoch 2/5\n",
      "255/255 [==============================] - 62s 244ms/step - loss: 28.9164 - mse: 226.3298 - mae: 11.3549 - val_loss: 29010.8047 - val_mse: 127560784.0000 - val_mae: 9264.8604\n",
      "Epoch 3/5\n",
      "255/255 [==============================] - 62s 244ms/step - loss: 27.9529 - mse: 213.8694 - mae: 11.0654 - val_loss: 28.3394 - val_mse: 160.2601 - val_mae: 10.1380\n",
      "Epoch 4/5\n",
      "255/255 [==============================] - 62s 244ms/step - loss: 27.8031 - mse: 214.6881 - mae: 11.0317 - val_loss: 26.4367 - val_mse: 224.4548 - val_mae: 11.0223\n",
      "Epoch 5/5\n",
      "255/255 [==============================] - 63s 248ms/step - loss: 27.5520 - mse: 215.5914 - mae: 11.0144 - val_loss: 35.6838 - val_mse: 246.6408 - val_mae: 12.3185\n"
     ]
    }
   ],
   "source": [
    "history2 = resnet.fit(train_images,train_labels, epochs=5, batch_size=16,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MTST22NsNr30",
    "outputId": "423ce00d-a5db-464a-e310-4380db8711ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 127ms/step - loss: 35.4821 - mse: 237.3293 - mae: 12.2140\n"
     ]
    }
   ],
   "source": [
    "test_mape_resnet, test_mse_resnet, test_mae = resnet.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema de Inferência por imagem de input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo a rede definida e com este grau de taxa de sucesso, podemos passar a uma utilização mais prática da rede, onde é possivel carregar uma imagem local da máquina (que já se encontre em 256*256 pixeis) e testar a previsão da rede\n",
    "\n",
    "No exemplo abaixo a pessoa da foto possuia 18 anos. Pelo que podemos ver, não só pelas métricas de treino/teste como por este exemplo, a rede simplificada conseguiu uma performace superior à resnet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x2AA61B47148>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3],[0.2989,0.5870,0.1140])\n",
    "\n",
    "\n",
    "imgTeste = Image.open(\"dias.jpg\")\n",
    "data = np.asarray(imgTeste)/255\n",
    "if(len(data.shape)>2):\n",
    "    data = rgb2gray(data)\n",
    "img =  Image.fromarray((data*255).astype('uint8'))\n",
    "img2CNN =  data.reshape(1, 256, 256, 1)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.123446]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#previsão da rede simplificada\n",
    "model.predict(img2CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.686602]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#previsão da rede resNet50\n",
    "resnet.predict(img2CNN)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_AgeRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
